# mini_predict.py
import torch
from torchvision import transforms, models
from PIL import Image
import os

# ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ï¼ˆImageFolderã§èª­ã¿è¾¼ã‚“ã é †ï¼‰
class_names = ['burnable', 'plastic', 'pet', 'cardboard']

# ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰ã—ã¦èª­ã¿è¾¼ã‚€
model = models.mobilenet_v2(weights=None)
model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 4)
model.load_state_dict(torch.load('model.pth'))
model.eval()
 
# æ¨è«–ç”¨å‰å‡¦ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# æ¨è«–å¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
test_dir = 'testdata'
image_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]

# å„ç”»åƒã«å¯¾ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œ
for image_file in image_files:
    image_path = os.path.join(test_dir, image_file)
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§æ¨è«–
        img = Image.open(image_path).convert('RGB')
        img_tensor = transform(img).unsqueeze(0)

        # æ¨è«–å®Ÿè¡Œ
        with torch.no_grad():
            outputs = model(img_tensor)
            predicted = outputs.argmax(1).item()
            confidence = torch.nn.functional.softmax(outputs, dim=1)[0][predicted].item()

        print(f"ğŸ“¸ ç”»åƒ: {image_file}")
        print(f"ğŸ§  äºˆæ¸¬: {class_names[predicted]} (ç¢ºä¿¡åº¦: {confidence:.2%})")
        print("-" * 50)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ ({image_file}): {str(e)}")
        print("-" * 50)
